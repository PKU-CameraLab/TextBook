{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "tf.disable_eager_execution()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Param Choice\n",
    "\n",
    "**Note your input should crop and resize to 372*540**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters\n",
    "lfsize = [372, 540, 8, 8] #dimensions of light fields\n",
    "batchsize = 1 \n",
    "disp_mult = 4.0 #max disparity between adjacent veiws\n",
    "checkpoint = 'checkpoints/model.ckpt-499' #path to store checkpoints\n",
    "input_dir = 'input'# input dir\n",
    "outdir = \"output/\" # output dir"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#functions for CNN layers\n",
    "\n",
    "def weight_variable(w_shape):\n",
    "    return tf.get_variable('weights', w_shape, initializer=tf.keras.initializers.glorot_normal())\n",
    "\n",
    "def bias_variable(b_shape, init_bias=0.0):\n",
    "    return tf.get_variable('bias', b_shape, initializer=tf.constant_initializer(init_bias))\n",
    "\n",
    "def cnn_layer(input_tensor, w_shape, b_shape, layer_name, rate=1, ds=1):\n",
    "    with tf.variable_scope(layer_name):\n",
    "        W = weight_variable(w_shape)\n",
    "        pad_amt_0 = rate * (w_shape[0] - 1)//2\n",
    "        pad_amt_1 = rate * (w_shape[1] - 1)//2\n",
    "        input_tensor = tf.pad(input_tensor, [[0,0],[pad_amt_0,pad_amt_0],[pad_amt_1,pad_amt_1],[0,0]], mode='SYMMETRIC')\n",
    "        h = tf.nn.convolution(input_tensor, W, strides=[ds, ds], padding='VALID', dilation_rate=[rate, rate], name=layer_name + '_conv')\n",
    "        h = tfa.layers.InstanceNormalization()(h + bias_variable(b_shape))\n",
    "        h = tf.nn.leaky_relu(h)\n",
    "        return h\n",
    "    \n",
    "def cnn_layer_plain(input_tensor, w_shape, b_shape, layer_name, rate=1, ds=1):\n",
    "    with tf.variable_scope(layer_name):\n",
    "        W = weight_variable(w_shape)\n",
    "        pad_amt_0 = rate * (w_shape[0] - 1)//2\n",
    "        pad_amt_1 = rate * (w_shape[1] - 1)//2\n",
    "        input_tensor = tf.pad(input_tensor, [[0,0],[pad_amt_0,pad_amt_0],[pad_amt_1,pad_amt_1],[0,0]], mode='SYMMETRIC')\n",
    "        h = tf.nn.convolution(input_tensor, W, strides=[ds, ds], padding='VALID', dilation_rate=[rate, rate], name=layer_name + '_conv')\n",
    "        h = h + bias_variable(b_shape)\n",
    "        return h\n",
    "    \n",
    "def cnn_layer_3D(input_tensor, w_shape, b_shape, layer_name, rate=1, ds=1):\n",
    "    with tf.variable_scope(layer_name):\n",
    "        W = weight_variable(w_shape)\n",
    "        pad_amt_0 = rate * (w_shape[0] - 1)//2\n",
    "        pad_amt_1 = rate * (w_shape[1] - 1)//2\n",
    "        pad_amt_2 = rate * (w_shape[2] - 1)//2\n",
    "        input_tensor = tf.pad(input_tensor, [[0,0],[pad_amt_0,pad_amt_0],[pad_amt_1,pad_amt_1],[pad_amt_2,pad_amt_2],[0,0]], mode='SYMMETRIC')\n",
    "        h = tf.nn.convolution(input_tensor, W, strides=[ds, ds, ds], padding='VALID', dilation_rate=[rate, rate, rate], name=layer_name + '_conv')\n",
    "        h = tfa.layers.InstanceNormalization()(h + bias_variable(b_shape))\n",
    "        h = tf.nn.leaky_relu(h)\n",
    "        return h\n",
    "    \n",
    "def cnn_layer_3D_plain(input_tensor, w_shape, b_shape, layer_name, rate=1, ds=1):\n",
    "    with tf.variable_scope(layer_name):\n",
    "        W = weight_variable(w_shape)\n",
    "        pad_amt_0 = rate * (w_shape[0] - 1)//2\n",
    "        pad_amt_1 = rate * (w_shape[1] - 1)//2\n",
    "        pad_amt_2 = rate * (w_shape[2] - 1)//2\n",
    "        input_tensor = tf.pad(input_tensor, [[0,0],[pad_amt_0,pad_amt_0],[pad_amt_1,pad_amt_1],[pad_amt_2,pad_amt_2],[0,0]], mode='SYMMETRIC')\n",
    "        h = tf.nn.convolution(input_tensor, W, strides=[ds, ds, ds], padding='VALID', dilation_rate=[rate, rate, rate], name=layer_name + '_conv')\n",
    "        h = h + bias_variable(b_shape)\n",
    "        return h"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#network to predict ray depths from input image\n",
    "\n",
    "def depth_network(x, lfsize, disp_mult, name):\n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        b_sz = tf.shape(x)[0]\n",
    "        y_sz = tf.shape(x)[1]\n",
    "        x_sz = tf.shape(x)[2]\n",
    "        v_sz = lfsize[2]\n",
    "        u_sz = lfsize[3]\n",
    "        \n",
    "        c1 = cnn_layer(x, [3, 3, 3, 16], [16], 'c1')\n",
    "        c2 = cnn_layer(c1, [3, 3, 16, 64], [64], 'c2')\n",
    "        c3 = cnn_layer(c2, [3, 3, 64, 128], [128], 'c3')\n",
    "        c4 = cnn_layer(c3, [3, 3, 128, 128], [128], 'c4', rate=2)\n",
    "        c5 = cnn_layer(c4, [3, 3, 128, 128], [128], 'c5', rate=4)\n",
    "        c6 = cnn_layer(c5, [3, 3, 128, 128], [128], 'c6', rate=8)\n",
    "        c7 = cnn_layer(c6, [3, 3, 128, 128], [128], 'c7', rate=16)\n",
    "        c8 = cnn_layer(c7, [3, 3, 128, 128], [128], 'c8')\n",
    "        c9 = cnn_layer(c8, [3, 3, 128, lfsize[2]*lfsize[3]], [lfsize[2]*lfsize[3]], 'c9')\n",
    "        c10 = disp_mult*tf.tanh(cnn_layer_plain(c9, [3, 3, lfsize[2]*lfsize[3], lfsize[2]*lfsize[3]], \\\n",
    "                                                [lfsize[2]*lfsize[3]], 'c10'))\n",
    "        \n",
    "        return tf.reshape(c10, [b_sz, y_sz, x_sz, v_sz, u_sz])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#network for refining Lambertian light field (predict occluded rays and non-Lambertian effects)\n",
    "\n",
    "def occlusions_network(x, shear, lfsize, name):\n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        b_sz = tf.shape(x)[0]\n",
    "        y_sz = tf.shape(x)[1]\n",
    "        x_sz = tf.shape(x)[2]\n",
    "        v_sz = lfsize[2]\n",
    "        u_sz = lfsize[3]\n",
    "        \n",
    "        x = tf.transpose(tf.reshape(tf.transpose(x, perm=[0, 5, 1, 2, 3, 4]), \\\n",
    "                                    [b_sz, 4, y_sz, x_sz, u_sz*v_sz]), perm=[0, 4, 2, 3, 1])\n",
    "        \n",
    "        c1 = cnn_layer_3D(x, [3, 3, 3, 4, 8], [8], 'c1')\n",
    "        c2 = cnn_layer_3D(c1, [3, 3, 3, 8, 8], [8], 'c2')\n",
    "        c3 = cnn_layer_3D(c2, [3, 3, 3, 8, 8], [8], 'c3')\n",
    "        c4 = cnn_layer_3D(c3, [3, 3, 3, 8, 8], [8], 'c4')\n",
    "        c5 = tf.tanh(cnn_layer_3D_plain(c4, [3, 3, 3, 8, 3], [3], 'c5'))\n",
    "        \n",
    "        output = tf.transpose(tf.reshape(tf.transpose(c5, perm=[0, 4, 2, 3, 1]), \\\n",
    "                                         [b_sz, 3, y_sz, x_sz, v_sz, u_sz]), perm=[0, 2, 3, 4, 5, 1]) + shear\n",
    "                \n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#full forward model\n",
    "\n",
    "def forward_model(x, lfsize, disp_mult):\n",
    "    with tf.variable_scope('forward_model', reuse=tf.AUTO_REUSE) as scope:\n",
    "        #predict ray depths from input image\n",
    "        ray_depths = depth_network(x, lfsize, disp_mult, 'ray_depths')\n",
    "        #shear input image by predicted ray depths to render Lambertian light field\n",
    "        lf_shear_r = depth_rendering(x[:, :, :, 0], ray_depths, lfsize)\n",
    "        lf_shear_g = depth_rendering(x[:, :, :, 1], ray_depths, lfsize)\n",
    "        lf_shear_b = depth_rendering(x[:, :, :, 2], ray_depths, lfsize)\n",
    "        lf_shear = tf.stack([lf_shear_r, lf_shear_g, lf_shear_b], axis=5)\n",
    "        #occlusion/non-Lambertian prediction network\n",
    "        shear_and_depth = tf.stack([lf_shear_r, lf_shear_g, lf_shear_b, tf.stop_gradient(ray_depths)], axis=5)\n",
    "        y = occlusions_network(shear_and_depth, lf_shear, lfsize, 'occlusions')\n",
    "        return ray_depths, lf_shear, y"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#render light field from input image and ray depths\n",
    "\n",
    "def depth_rendering(central, ray_depths, lfsize):\n",
    "    with tf.variable_scope('depth_rendering') as scope:\n",
    "        b_sz = tf.shape(central)[0]\n",
    "        y_sz = tf.shape(central)[1]\n",
    "        x_sz = tf.shape(central)[2]\n",
    "        u_sz = lfsize[2]\n",
    "        v_sz = lfsize[3]\n",
    "        \n",
    "        central = tf.expand_dims(tf.expand_dims(central, 3), 4)\n",
    "                                                \n",
    "        #create and reparameterize light field grid\n",
    "        b_vals = tf.to_float(tf.range(b_sz))\n",
    "        v_vals = tf.to_float(tf.range(v_sz)) - tf.to_float(v_sz)/2.0\n",
    "        u_vals = tf.to_float(tf.range(u_sz)) - tf.to_float(u_sz)/2.0\n",
    "        y_vals = tf.to_float(tf.range(y_sz))\n",
    "        x_vals = tf.to_float(tf.range(x_sz))\n",
    "    \n",
    "        b, y, x, v, u = tf.meshgrid(b_vals, y_vals, x_vals, v_vals, u_vals, indexing='ij')\n",
    "               \n",
    "        #warp coordinates by ray depths\n",
    "        y_t = y + v * ray_depths\n",
    "        x_t = x + u * ray_depths\n",
    "        \n",
    "        v_r = tf.zeros_like(b)\n",
    "        u_r = tf.zeros_like(b)\n",
    "        \n",
    "        #indices for linear interpolation\n",
    "        b_1 = tf.to_int32(b)\n",
    "        y_1 = tf.to_int32(tf.floor(y_t))\n",
    "        y_2 = y_1 + 1\n",
    "        x_1 = tf.to_int32(tf.floor(x_t))\n",
    "        x_2 = x_1 + 1\n",
    "        v_1 = tf.to_int32(v_r)\n",
    "        u_1 = tf.to_int32(u_r)\n",
    "        \n",
    "        y_1 = tf.clip_by_value(y_1, 0, y_sz-1)\n",
    "        y_2 = tf.clip_by_value(y_2, 0, y_sz-1)\n",
    "        x_1 = tf.clip_by_value(x_1, 0, x_sz-1)\n",
    "        x_2 = tf.clip_by_value(x_2, 0, x_sz-1)\n",
    "        \n",
    "        #assemble interpolation indices\n",
    "        interp_pts_1 = tf.stack([b_1, y_1, x_1, v_1, u_1], -1)\n",
    "        interp_pts_2 = tf.stack([b_1, y_2, x_1, v_1, u_1], -1)\n",
    "        interp_pts_3 = tf.stack([b_1, y_1, x_2, v_1, u_1], -1)\n",
    "        interp_pts_4 = tf.stack([b_1, y_2, x_2, v_1, u_1], -1)\n",
    "        \n",
    "        #gather light fields to be interpolated\n",
    "        lf_1 = tf.gather_nd(central, interp_pts_1)\n",
    "        lf_2 = tf.gather_nd(central, interp_pts_2)\n",
    "        lf_3 = tf.gather_nd(central, interp_pts_3)\n",
    "        lf_4 = tf.gather_nd(central, interp_pts_4)\n",
    "        \n",
    "        #calculate interpolation weights\n",
    "        y_1_f = tf.to_float(y_1)\n",
    "        x_1_f = tf.to_float(x_1)\n",
    "        d_y_1 = 1.0 - (y_t - y_1_f)\n",
    "        d_y_2 = 1.0 - d_y_1\n",
    "        d_x_1 = 1.0 - (x_t - x_1_f)\n",
    "        d_x_2 = 1.0 - d_x_1\n",
    "        \n",
    "        w1 = d_y_1 * d_x_1\n",
    "        w2 = d_y_2 * d_x_1\n",
    "        w3 = d_y_1 * d_x_2\n",
    "        w4 = d_y_2 * d_x_2\n",
    "        \n",
    "        lf = tf.add_n([w1*lf_1, w2*lf_2, w3*lf_3, w4*lf_4])\n",
    "                        \n",
    "    return lf"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#resample ray depths for depth consistency regularization\n",
    "\n",
    "def transform_ray_depths(ray_depths, u_step, v_step, lfsize):\n",
    "    with tf.variable_scope('transform_ray_depths') as scope:\n",
    "        b_sz = tf.shape(ray_depths)[0]\n",
    "        y_sz = tf.shape(ray_depths)[1]\n",
    "        x_sz = tf.shape(ray_depths)[2]\n",
    "        u_sz = lfsize[2]\n",
    "        v_sz = lfsize[3]\n",
    "                                                        \n",
    "        #create and reparameterize light field grid\n",
    "        b_vals = tf.to_float(tf.range(b_sz))\n",
    "        v_vals = tf.to_float(tf.range(v_sz)) - tf.to_float(v_sz)/2.0\n",
    "        u_vals = tf.to_float(tf.range(u_sz)) - tf.to_float(u_sz)/2.0\n",
    "        y_vals = tf.to_float(tf.range(y_sz))\n",
    "        x_vals = tf.to_float(tf.range(x_sz))\n",
    "    \n",
    "        b, y, x, v, u = tf.meshgrid(b_vals, y_vals, x_vals, v_vals, u_vals, indexing='ij')\n",
    "               \n",
    "        #warp coordinates by ray depths\n",
    "        y_t = y + v_step * ray_depths\n",
    "        x_t = x + u_step * ray_depths\n",
    "        \n",
    "        v_t = v - v_step + tf.to_float(v_sz)/2.0\n",
    "        u_t = u - u_step + tf.to_float(u_sz)/2.0\n",
    "        \n",
    "        #indices for linear interpolation\n",
    "        b_1 = tf.to_int32(b)\n",
    "        y_1 = tf.to_int32(tf.floor(y_t))\n",
    "        y_2 = y_1 + 1\n",
    "        x_1 = tf.to_int32(tf.floor(x_t))\n",
    "        x_2 = x_1 + 1\n",
    "        v_1 = tf.to_int32(v_t)\n",
    "        u_1 = tf.to_int32(u_t)\n",
    "        \n",
    "        y_1 = tf.clip_by_value(y_1, 0, y_sz-1)\n",
    "        y_2 = tf.clip_by_value(y_2, 0, y_sz-1)\n",
    "        x_1 = tf.clip_by_value(x_1, 0, x_sz-1)\n",
    "        x_2 = tf.clip_by_value(x_2, 0, x_sz-1)\n",
    "        v_1 = tf.clip_by_value(v_1, 0, v_sz-1)\n",
    "        u_1 = tf.clip_by_value(u_1, 0, u_sz-1)\n",
    "        \n",
    "        #assemble interpolation indices\n",
    "        interp_pts_1 = tf.stack([b_1, y_1, x_1, v_1, u_1], -1)\n",
    "        interp_pts_2 = tf.stack([b_1, y_2, x_1, v_1, u_1], -1)\n",
    "        interp_pts_3 = tf.stack([b_1, y_1, x_2, v_1, u_1], -1)\n",
    "        interp_pts_4 = tf.stack([b_1, y_2, x_2, v_1, u_1], -1)\n",
    "        \n",
    "        #gather light fields to be interpolated\n",
    "        lf_1 = tf.gather_nd(ray_depths, interp_pts_1)\n",
    "        lf_2 = tf.gather_nd(ray_depths, interp_pts_2)\n",
    "        lf_3 = tf.gather_nd(ray_depths, interp_pts_3)\n",
    "        lf_4 = tf.gather_nd(ray_depths, interp_pts_4)\n",
    "        \n",
    "        #calculate interpolation weights\n",
    "        y_1_f = tf.to_float(y_1)\n",
    "        x_1_f = tf.to_float(x_1)\n",
    "        d_y_1 = 1.0 - (y_t - y_1_f)\n",
    "        d_y_2 = 1.0 - d_y_1\n",
    "        d_x_1 = 1.0 - (x_t - x_1_f)\n",
    "        d_x_2 = 1.0 - d_x_1\n",
    "        \n",
    "        w1 = d_y_1 * d_x_1\n",
    "        w2 = d_y_2 * d_x_1\n",
    "        w3 = d_y_1 * d_x_2\n",
    "        w4 = d_y_2 * d_x_2\n",
    "        \n",
    "        lf = tf.add_n([w1*lf_1, w2*lf_2, w3*lf_3, w4*lf_4])\n",
    "                        \n",
    "    return lf"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#loss to encourage consistency of ray depths corresponding to same scene point\n",
    "\n",
    "def depth_consistency_loss(x, lfsize):\n",
    "    x_u = transform_ray_depths(x, 1.0, 0.0, lfsize)\n",
    "    x_v = transform_ray_depths(x, 0.0, 1.0, lfsize)\n",
    "    x_uv = transform_ray_depths(x, 1.0, 1.0, lfsize)\n",
    "    d1 = (x[:,:,:,1:,1:]-x_u[:,:,:,1:,1:])\n",
    "    d2 = (x[:,:,:,1:,1:]-x_v[:,:,:,1:,1:])\n",
    "    d3 = (x[:,:,:,1:,1:]-x_uv[:,:,:,1:,1:])\n",
    "    l1 = tf.reduce_mean(tf.abs(d1)+tf.abs(d2)+tf.abs(d3))\n",
    "    return l1"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#normalize to between -1 and 1, given input between 0 and 1\n",
    "\n",
    "def normalize_lf(lf):\n",
    "    return 2.0*(lf-0.5)\n",
    "\n",
    "def to_img(img):\n",
    "    img_ = np.reshape(np.transpose(img, [0, 3, 4, 1, 2, 5]), [64, lfsize[0], lfsize[1], 3])\n",
    "    img__ = img_ - np.min(img_)\n",
    "    return img__ / np.max(img__)\n",
    "\n",
    "def save_img(img,out_dir):\n",
    "    for i in range(64):\n",
    "        if (i // 8) % 2 == 0:\n",
    "            j = i\n",
    "        else:\n",
    "            j = ((i // 8) + 1) * 8 - (i % 8) - 1\n",
    "        PILImage.fromarray((img[j] * 255).astype(np.uint8)).save(f\"{out_dir}/%03d.png\" % i)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_graph():\n",
    "    input_image = tf.placeholder(shape=[1] + lfsize[:2] + [3], dtype=tf.float32)\n",
    "    _, _, y = forward_model(input_image, lfsize, disp_mult)\n",
    "    return input_image, y\n",
    "\n",
    "input_image_ph, y_ph = build_graph()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess,checkpoint)\n",
    "    for filename in os.listdir(input_dir):\n",
    "        input_image_path = os.path.join(input_dir,filename)\n",
    "        input_image = normalize_lf(np.array(PILImage.open(input_image_path).convert(\"RGB\")).astype(np.float32))\n",
    "        [y] = sess.run([y_ph], feed_dict={input_image_ph:input_image[None]})\n",
    "        if not os.path.exists(outdir + filename[:-4]):\n",
    "            os.makedirs(outdir + filename[:-4])\n",
    "        save_img(to_img(y),out_dir=outdir + filename[:-4])\n",
    "        print(\"test image: %s\"%filename)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "6fac42edfc09301284e1685d27405067f0644082ca9e3bc8b9ce7ba5e691ae08"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}